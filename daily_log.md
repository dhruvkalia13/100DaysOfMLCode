# Daily progress

## Day 1

* Importing libraries
* Importing dataset
* Handling missing values
    * by dropping columns
    * by imputing values
    * by extending imputation

## Day 2

* Handling categorical values
    * by dropping columns
    * by label encoding
    * by one-hot encoding

## Day 3

* Splitting dataset
* Feature Scaling
    * Normalization
    * Standardization
    
## Day 4

* Simple Linear Regression

## Day 5

* Multiple Linear Regression

## Day 6

* Stepwise Regression (Backward Elimination)

## Day 7

* Polynomial Regression

## Day 8

* SVM Regression
    * Linear regression
    * Non-linear regression

## Day 9

* Decision Tree Regression

## Day 10

* Random Forest Regression

## Day 11

* Logistic Regression

## Day 12

* K Nearest Neighbour

## Day 13

* SVM Classifier (Linear)

## Day 14

* SVM Classifier (Non-linear)

## Day 15

* Naive Bayes Classification

## Day 16

* Decision Tree Classifier

## Day 17

* Random Forest Classifier

## Day 18

* K Means Clustering

## Day 19

* DBSCAN Clustering

## Day 20

* Mean Shift Clustering

## Day 21

* Introduction to ANN
* Perceptron

## Day 22

* Multilayer Perceptron
* Backpropagation Algorithm

## Day 23

* Sequential API (Classification MLP)

## Day 24

* Tuning the model
* Making predictions

## Day 25

* Sequential API (Regression MLP)

## Day 26

* Functional API (Regression MLP)

## Day 27

* Saving and restoring a model
* Callbacks
* Visualizing logs in Tensorboard

## Day 28

* Fine tuning neural network hyperparameters
* RandomizedSearchCV

## Day 29

* Importance of optimizer and loss function

## Day 30

* Batch Normalization

## Day 31

* Customer Churn
* Transfer Learning

## Day 32

* Added visualizations in Customer Churn
* Momentum optimization

## Day 33

* AdaGrad and RMSProp

## Day 34

* Adam and Nadam Optimization

## Day 35

* Learning Rate Scheduling

## Day 36

* Learning Rate Scheduling (Impl)

## Day 37

* Convolution Layers (CNN)

## Day 38

* Zero Padding, Strides, Filters
* CNN basic implementation

## Day 39

* Pooling Layers (CNN)
* CNN Architecture
* CNN (Fashion MNIST dataset)

## Day 40

* Predicting CNN (Fashion MNIST dataset)
* LeNet-5
* Data Augmentation

## Day 41

* Using pretrained models from keras
* Image classification using ResNet

## Day 42

* Using pretrained models for transfer learning
* Image classification using Xception layers

## Day 43

* Classification and Localization
* Object detection

## Day 44

* R-CNN

## Day 45

* Object detection using R-CNN (Implementation)

## Day 46

* Comparison between R-CNN, R-CNN Fast and R-CNN Faster
* Selective search
* Region Proposal Network

## Day 47

* Image Segmentation

## Day 48

* Starting with RNNs
* Recurrent Neurons

## Day 49

* Memory Cells in RNN
* Input and output Sequences

## Day 50

* Time Series (Univariate and Multivariate)
* Simple RNN Model

## Day 51

* Google Stock Prediction using RNN

## Day 52

* Unstable Gradients Problem
* Layer Normalization

## Day 53

* Exploring SimpleRNN more

## Day 54

* LSTM (Long Short Term Memory) Network

## Day 55

* Exploring LSTM more
